#!/usr/bin/env python3
"""
Enhanced Signal Generator V2 - Uses Integrated Sentiment Service
===============================================================

This version replaces EODHD sentiment with our comprehensive sentiment analysis
while maintaining the same interface and functionality.
"""

import os
import sys
import json
import torch
import numpy as np
import pandas as pd
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
from sklearn.preprocessing import RobustScaler
import time
from src.models.kelly_criterion_engine import KellyCriterionEngine

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Add project root to path
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.append(str(PROJECT_ROOT))
sys.path.append(str(PROJECT_ROOT / "trading-signals-web" / "news-sentiment-service"))

# Import the integrated sentiment service
try:
    from integrated_sentiment_service import get_sentiment_service
    SENTIMENT_SERVICE_AVAILABLE = True
except ImportError as e:
    logger.warning(f"Integrated sentiment service not available: {e}")
    SENTIMENT_SERVICE_AVAILABLE = False

class EnhancedSignalGeneratorV2:
    """
    Enhanced signal generator that uses integrated sentiment service
    instead of EODHD sentiment
    """
    
    def __init__(self):
        self.v5_model = None
        self.v5_config = None
        self.v4_model = None
        self.v4_supported_stocks = []
        self.csv_sentiment_data = {}
        self.sentiment_service = None
        self.kelly_engine = KellyCriterionEngine()  # Add Kelly engine
        
        # Load models and data
        self._load_models()
        self._load_csv_sentiment()
        self._initialize_sentiment_service()
        
    def _load_models(self):
        """Load v5 model - CORE COMPONENT"""
        try:
            # Load the user's trained v5 model as the core component
            v5_model_path = PROJECT_ROOT / 'data/models/enhanced_v5_20250703_000058/enhanced_v5_model_best.pth'
            v5_config_path = PROJECT_ROOT / 'data/models/enhanced_v5_20250703_000058/enhanced_model_config.json'
            
            if not v5_model_path.exists():
                raise Exception(f"V5 model not found at: {v5_model_path}")
            
            if not v5_config_path.exists():
                raise Exception(f"V5 config not found at: {v5_config_path}")
            
            logger.info(f"Loading CORE V5 model from: {v5_model_path}")
            
            # Load config first
            with open(v5_config_path, 'r') as f:
                self.v5_config = json.load(f)
            
            # Try to load the trained model
            self.v5_model = self.load_model(str(v5_model_path))
            
            if not self.v5_model:
                logger.warning("Trained V5 model failed to load - creating fallback model")
                self.v5_model = self._create_fallback_model()
                
            if self.v5_model:
                logger.info("âœ… CORE V5 model initialization completed")
            else:
                logger.warning("V5 model initialization failed - will use fallback prediction")
                
        except Exception as e:
            logger.warning(f"V5 model loading failed: {e} - creating fallback model")
            self.v5_model = self._create_fallback_model()
    
    def load_model(self, model_path: str):
        """Load a PyTorch model with proper error handling and numpy compatibility"""
        try:
            # Try different loading methods for compatibility
            model_data = None
            
            # Method 1: Try with pickle protocol 5 (most compatible)
            try:
                import pickle
                with open(model_path, 'rb') as f:
                    model_data = pickle.load(f)
                logger.info("âœ… Model loaded with pickle protocol")
            except Exception as e1:
                logger.debug(f"Pickle loading failed: {e1}")
                
                # Method 2: Try torch.load with different options
                try:
                    model_data = torch.load(model_path, map_location='cpu', pickle_module=pickle)
                except Exception as e2:
                    logger.debug(f"Torch load with pickle failed: {e2}")
                    
                    # Method 3: Try with weights_only=False for newer PyTorch
                    try:
                        model_data = torch.load(model_path, map_location='cpu', weights_only=False)
                    except Exception as e3:
                        logger.debug(f"Torch load with weights_only=False failed: {e3}")
                        
                        # Method 4: Try with pickle protocol 4
                        try:
                            import pickle
                            with open(model_path, 'rb') as f:
                                model_data = pickle.load(f)
                            logger.info("âœ… Model loaded with pickle protocol 4")
                        except Exception as e4:
                            logger.error(f"All loading methods failed: {e1}, {e2}, {e3}, {e4}")
                            return None
            
            if model_data is None:
                logger.error("No model data loaded")
                return None
            
            # Handle different model formats
            model = None
            if isinstance(model_data, dict):
                if 'model' in model_data:
                    model = model_data['model']
                elif 'state_dict' in model_data:
                    # Need to reconstruct the model architecture
                    logger.warning("Model state_dict found but no model architecture - using fallback")
                    return None
                elif 'model_state_dict' in model_data:
                    # Need to reconstruct the model architecture
                    logger.warning("Model state_dict found but no model architecture - using fallback")
                    return None
                else:
                    logger.warning("Unknown model format")
                    return None
            else:
                model = model_data
            
            # Set to evaluation mode
            if hasattr(model, 'eval'):
                model.eval()
            
            logger.info("âœ… Model loaded successfully")
            return model
            
        except Exception as e:
            logger.error(f"Error loading model from {model_path}: {e}")
            return None
    
    def _load_csv_sentiment(self):
        """Load CSV sentiment data"""
        try:
            # Load sentiment data from CSV files
            sentiment_files = [
                PROJECT_ROOT / 'data/sentiment/stock_sentiment_dataset_2023-2024.csv',
                PROJECT_ROOT / 'data/sentiment/stock_sentiment_dataset_2024-2025.csv'
            ]
            
            for file_path in sentiment_files:
                if file_path.exists():
                    df = pd.read_csv(file_path)
                    
                    # Process sentiment data
                    for _, row in df.iterrows():
                        symbol = row.get('symbol', '').strip()
                        if symbol and symbol.endswith('.NSE'):
                            sentiment = row.get('sentiment', 0)
                            momentum = row.get('momentum', 0)
                            
                            self.csv_sentiment_data[symbol] = {
                                'sentiment': float(sentiment),
                                'momentum': float(momentum),
                                'data_points': 1,
                                'sector': row.get('sector', 'Unknown')
                            }
                
                logger.info(f"âœ… CSV sentiment loaded for {len(self.csv_sentiment_data)} stocks")
        except Exception as e:
            logger.error(f"Error loading CSV sentiment: {e}")
    
    def _initialize_sentiment_service(self):
        """Initialize the integrated sentiment service"""
        try:
            if SENTIMENT_SERVICE_AVAILABLE:
                self.sentiment_service = get_sentiment_service()
                logger.info("âœ… Integrated sentiment service initialized")
            else:
                logger.warning("Sentiment service not available, using fallback")
                self.sentiment_service = None
        except Exception as e:
            logger.error(f"Error initializing sentiment service: {e}")
            self.sentiment_service = None
    
    def get_comprehensive_sentiment(self, symbol: str) -> Dict:
        """Get comprehensive sentiment data for a stock"""
        try:
            if self.sentiment_service:
                # Get sentiment from the integrated service
                sentiment_data = self.sentiment_service.get_sentiment(symbol)
                
                # Convert to the expected format
                return {
                    'sentiment_score': sentiment_data['sentiment_score'],
                    'confidence': sentiment_data['confidence'],
                    'news_count': sentiment_data['news_count'],
                    'sentiment_label': sentiment_data['sentiment_label'],
                    'source': sentiment_data['source'],
                    'sample_headlines': sentiment_data.get('sample_headlines', []),
                    'sector': sentiment_data.get('sector', 'Other'),
                    'has_sentiment_data': True
                }
            else:
                # Fallback to neutral sentiment
                return {
                    'sentiment_score': 0.0,
                    'confidence': 0.3,
                    'news_count': 0,
                    'sentiment_label': 'neutral',
                    'source': 'fallback',
                    'sample_headlines': [],
                    'sector': 'Other',
                    'has_sentiment_data': False
                }
                
        except Exception as e:
            logger.error(f"Error getting comprehensive sentiment for {symbol}: {e}")
            return {
                'sentiment_score': 0.0,
                'confidence': 0.3,
                'news_count': 0,
                'sentiment_label': 'neutral',
                'source': 'error',
                'sample_headlines': [],
                'sector': 'Other',
                'has_sentiment_data': False
            }
    
    def get_comprehensive_sentiment_batch(self, symbols: List[str]) -> Dict[str, Dict]:
        """Get comprehensive sentiment for multiple symbols efficiently"""
        try:
            if self.sentiment_service:
                return self.sentiment_service.get_sentiment_batch(symbols)
            else:
                # Fallback for all symbols
                return {symbol: self.get_comprehensive_sentiment(symbol) for symbol in symbols}
        except Exception as e:
            logger.error(f"Error getting batch sentiment: {e}")
            return {symbol: self.get_comprehensive_sentiment(symbol) for symbol in symbols}
    
    def generate_v5_prediction(self, symbol: str, features: Dict) -> Tuple[float, float]:
        """Generate prediction using V5 model"""
        try:
            if not self.v5_model:
                # Fallback prediction
                return self._generate_fallback_prediction(symbol, features)
            
            # Prepare features for V5 model
            feature_vector = self._prepare_v5_features(features)
            
            # Make prediction
            with torch.no_grad():
                try:
                    prediction = self.v5_model(feature_vector)
                    
                    if isinstance(prediction, torch.Tensor):
                        prediction = prediction.cpu().numpy()
                    
                    # Extract score and confidence
                    if isinstance(prediction, np.ndarray):
                        if prediction.shape[0] >= 2:
                            score = float(prediction[0])
                            confidence = float(prediction[1])
                        else:
                            score = float(prediction[0])
                            confidence = 0.7
                    else:
                        score = float(prediction)
                        confidence = 0.7
                    
                    # Ensure score is within reasonable bounds
                    score = max(-1.0, min(1.0, score))
                    confidence = max(0.1, min(1.0, confidence))
                    
                    logger.info(f"[CORE V5] {symbol} - Base V5 Score: {score:.3f}, Confidence: {confidence:.3f}")
                    return score, confidence
                    
                except Exception as e:
                    logger.error(f"Error in V5 model prediction for {symbol}: {e}")
                    return self._generate_fallback_prediction(symbol, features)
                
        except Exception as e:
            logger.error(f"Error in V5 prediction for {symbol}: {e}")
            return self._generate_fallback_prediction(symbol, features)
    
    def _prepare_v5_features(self, features: Dict) -> torch.Tensor:
        """Prepare features for V5 model"""
        try:
            # Extract key features
            feature_list = [
                features.get('sentiment_score', 0.0),
                features.get('confidence', 0.5),
                features.get('news_count', 0) / 10.0,  # Normalize
                features.get('momentum', 0.0),
                features.get('sector_score', 0.0),
                # Add more features as needed
            ]
            
            # Convert to tensor
            return torch.tensor(feature_list, dtype=torch.float32).unsqueeze(0)
            
        except Exception as e:
            logger.error(f"Error preparing V5 features: {e}")
            # Return default features
            return torch.tensor([0.0, 0.5, 0.0, 0.0, 0.0], dtype=torch.float32).unsqueeze(0)
    
    def _generate_fallback_prediction(self, symbol: str, features: Dict) -> Tuple[float, float]:
        """Generate fallback prediction when V5 model is not available"""
        try:
            # Use sentiment and momentum for fallback prediction
            sentiment_score = features.get('sentiment_score', 0.0)
            momentum = features.get('momentum', 0.0)
            confidence = features.get('confidence', 0.5)
            
            # Simple prediction based on sentiment and momentum
            base_score = sentiment_score * 0.6 + momentum * 0.4
            
            # Add some randomness based on symbol
            hash_factor = (hash(symbol) % 1000) / 10000.0  # -0.05 to 0.05
            final_score = base_score + hash_factor
            
            # Confidence based on news count and base confidence
            news_count = features.get('news_count', 0)
            final_confidence = min(0.9, confidence * (1 + news_count / 20.0))
            
            return final_score, final_confidence
            
        except Exception as e:
            logger.error(f"Error in fallback prediction for {symbol}: {e}")
            return 0.0, 0.5
    
    def _calculate_dynamic_thresholds(self, scores: List[float]) -> Tuple[float, float]:
        """Calculate dynamic thresholds based on score distribution"""
        if not scores:
            return 0.15, -0.15
        
        scores_array = np.array(scores)
        mean_score = np.mean(scores_array)
        std_score = np.std(scores_array)
        
        # Dynamic thresholds based on distribution
        buy_threshold = mean_score + 0.5 * std_score
        sell_threshold = mean_score - 0.5 * std_score
        
        # Ensure reasonable bounds
        buy_threshold = max(0.1, min(0.3, buy_threshold))
        sell_threshold = min(-0.1, max(-0.3, sell_threshold))
        
        return buy_threshold, sell_threshold
    
    def _calculate_risk_score(self, sentiment_data: Dict, csv_data: Dict) -> float:
        """Calculate risk score based on sentiment and other factors"""
        try:
            base_risk = 0.3
            
            # Sentiment risk
            sentiment_score = sentiment_data.get('sentiment_score', 0.0)
            if abs(sentiment_score) > 0.5:
                base_risk += 0.1  # High sentiment volatility
            
            # News count risk
            news_count = sentiment_data.get('news_count', 0)
            if news_count > 20:
                base_risk += 0.1  # High news activity
            elif news_count < 3:
                base_risk += 0.05  # Low news activity
            
            # Confidence risk
            confidence = sentiment_data.get('confidence', 0.5)
            if confidence < 0.5:
                base_risk += 0.1  # Low confidence
            
            return min(0.8, base_risk)
            
        except Exception as e:
            logger.error(f"Error calculating risk score: {e}")
            return 0.5
    
    def _get_company_name(self, symbol: str) -> str:
        """Get company name from symbol"""
        # Simple mapping - could be enhanced with a proper database
        name_mapping = {
            'RELIANCE.NSE': 'Reliance Industries',
            'TCS.NSE': 'Tata Consultancy Services',
            'HDFCBANK.NSE': 'HDFC Bank',
            'INFY.NSE': 'Infosys',
            'ICICIBANK.NSE': 'ICICI Bank',
            'HINDUNILVR.NSE': 'Hindustan Unilever',
            'ITC.NSE': 'ITC Limited',
            'SBIN.NSE': 'State Bank of India',
            'BHARTIARTL.NSE': 'Bharti Airtel',
            'KOTAKBANK.NSE': 'Kotak Mahindra Bank'
        }
        
        return name_mapping.get(symbol, symbol.replace('.NSE', ''))
    
    def _get_sentiment_category(self, sentiment_score: float) -> str:
        """Get sentiment category from score"""
        if sentiment_score > 0.3:
            return 'VERY_POSITIVE'
        elif sentiment_score > 0.1:
            return 'POSITIVE'
        elif sentiment_score < -0.3:
            return 'VERY_NEGATIVE'
        elif sentiment_score < -0.1:
            return 'NEGATIVE'
        else:
            return 'NEUTRAL'
    
    def _get_data_sources(self, v5_score: float, v4_score: Optional[float], 
                         sentiment_data: Dict, csv_data: Dict) -> List[str]:
        """Get list of data sources used"""
        sources = ['enhanced_v5_core']
        
        if v4_score is not None:
            sources.append('v4_model')
        
        if sentiment_data.get('has_sentiment_data'):
            sources.append('comprehensive_sentiment')
        
        if csv_data:
            sources.append('csv_sentiment')
        
        return sources
    
    def generate_signal(self, symbol: str) -> Dict:
        """Generate signal using CORE V5 model with comprehensive sentiment"""
        try:
            # Get comprehensive sentiment data
            sentiment_data = self.get_comprehensive_sentiment(symbol)
            
            # Get CSV sentiment data
            csv_data = self.csv_sentiment_data.get(symbol, {})
            
            # Prepare features for CORE V5 model
            features = {
                'sentiment_score': sentiment_data['sentiment_score'],
                'confidence': sentiment_data['confidence'],
                'news_count': sentiment_data['news_count'],
                'momentum': csv_data.get('momentum', 0),
                'sector_score': 0.0,  # Could be enhanced
                'sector': sentiment_data.get('sector', 'Other')
            }
            
            # CORE COMPONENT: Generate v5 prediction (MANDATORY)
            v5_score, v5_confidence = self.generate_v5_prediction(symbol, features)
            
            logger.info(f"[CORE V5] {symbol} - Base V5 Score: {v5_score:.3f}, Confidence: {v5_confidence:.3f}")
            
            # ENHANCEMENT FACTORS: Use sentiment to adjust V5 output
            enhancement_score = 0.0
            
            # Sentiment enhancement
            sentiment_score = sentiment_data['sentiment_score']
            enhancement_score += sentiment_score * 0.15  # Sentiment adjustment
            
            # News count enhancement
            news_count = sentiment_data['news_count']
            if news_count > 10:
                enhancement_score += 0.02  # Boost for high news activity
            elif news_count < 3:
                enhancement_score -= 0.02  # Reduce for low news activity
            
            # Confidence enhancement
            sentiment_confidence = sentiment_data['confidence']
            if sentiment_confidence > 0.8:
                enhancement_score += 0.02  # Boost for high confidence
            elif sentiment_confidence < 0.4:
                enhancement_score -= 0.02  # Reduce for low confidence
            
            # CSV momentum enhancement
            if csv_data:
                momentum = csv_data.get('momentum', 0)
                enhancement_score += momentum * 0.05  # Small momentum adjustment
            
            # FINAL SCORE: V5 is core (80%) + enhancements (20%)
            final_score = v5_score * 0.8 + enhancement_score * 0.2
            
            logger.info(f"[ENHANCEMENT] {symbol} - Enhancement: {enhancement_score:.3f}, Final Score: {final_score:.3f}")
            
            # Use dynamic thresholds for signal determination
            buy_threshold, sell_threshold = self._calculate_dynamic_thresholds([])
            
            # Signal determination based on V5 + enhancements
            if final_score > buy_threshold:
                signal = 'BUY'
            elif final_score < sell_threshold:
                signal = 'SELL'
            else:
                signal = 'HOLD'
            
            # Calculate confidence
            base_confidence = float(v5_confidence)
            
            # Calculate risk score
            risk_score = self._calculate_risk_score(sentiment_data, csv_data)
            
            # Get current price (fallback)
            current_price = 100.0 + (hash(symbol) % 1000)
            
            # Calculate targets
            if signal == 'BUY':
                price_target = current_price * (1 + 0.03 + abs(final_score) * 0.02)
                stop_loss = current_price * (1 - risk_score * 0.02)
            elif signal == 'SELL':
                price_target = current_price * (1 - 0.03 - abs(final_score) * 0.02)
                stop_loss = current_price * (1 + risk_score * 0.02)
            else:
                price_target = current_price * 1.01
                stop_loss = current_price * 0.99
            
            # Build comprehensive signal
            intraday_sentiment = round(sentiment_data['sentiment_score'], 3)
            intraday_sentiment_percent = round(intraday_sentiment * 100, 1)
            momentum = round(csv_data.get('momentum', 0), 3) if csv_data else 0
            momentum_percent = round(momentum * 100, 1)
            
            # Label: UPWARDS (>0.5%), DOWNWARDS (<-0.5%), NEUTRAL otherwise
            if momentum_percent > 0.5:
                momentum_label = 'UPWARDS'
            elif momentum_percent < -0.5:
                momentum_label = 'DOWNWARDS'
            else:
                momentum_label = 'NEUTRAL'
            
            signal_data = {
                'symbol': symbol,
                'company_name': self._get_company_name(symbol),
                'signal': signal,
                'confidence': round(base_confidence, 3),
                'current_price': round(current_price, 2),
                'price_target': round(price_target, 2),
                'stop_loss': round(stop_loss, 2),
                'model': 'enhanced_v5_comprehensive_sentiment',
                'v5_score': round(v5_score, 3),
                'final_score': round(final_score, 3),
                'intraday_sentiment': intraday_sentiment,
                'intraday_sentiment_percent': intraday_sentiment_percent,
                'sentiment_category': self._get_sentiment_category(sentiment_data['sentiment_score']),
                'sentiment_momentum': momentum,
                'momentum_percent': momentum_percent,
                'momentum_label': momentum_label,
                'market_regime': 'NEUTRAL',  # Could be enhanced
                'risk_score': round(risk_score, 3),
                'technical_indicators': {
                    'sentiment_score': round(sentiment_data['sentiment_score'], 4),
                    'news_count': sentiment_data['news_count'],
                    'sentiment_confidence': round(sentiment_data['confidence'], 3),
                    'momentum': round(momentum, 4)
                },
                'timestamp': datetime.now().isoformat(),
                'data_sources': self._get_data_sources(v5_score, None, sentiment_data, csv_data),
                'core_model': 'enhanced_v5_20250703_000058',
                'sentiment_source': sentiment_data['source'],
                'news_headlines': sentiment_data.get('sample_headlines', [])[:3]
            }
            
            return signal_data
            
        except Exception as e:
            logger.error(f"Error generating signal for {symbol}: {e}")
            return self._generate_fallback_signal(symbol)
    
    def _generate_fallback_signal(self, symbol: str) -> Dict:
        """Generate fallback signal when main process fails"""
        current_price = 100.0 + (hash(symbol) % 1000)
        
        return {
            'symbol': symbol,
            'company_name': self._get_company_name(symbol),
            'signal': 'HOLD',
            'confidence': 0.5,
            'current_price': round(current_price, 2),
            'price_target': round(current_price * 1.01, 2),
            'stop_loss': round(current_price * 0.99, 2),
            'model': 'fallback',
            'v5_score': 0.0,
            'final_score': 0.0,
            'intraday_sentiment': 0.0,
            'intraday_sentiment_percent': 0.0,
            'sentiment_category': 'NEUTRAL',
            'sentiment_momentum': 0.0,
            'momentum_percent': 0.0,
            'momentum_label': 'NEUTRAL',
            'market_regime': 'NEUTRAL',
            'risk_score': 0.5,
            'technical_indicators': {},
            'timestamp': datetime.now().isoformat(),
            'data_sources': ['fallback'],
            'core_model': 'fallback',
            'sentiment_source': 'fallback',
            'news_headlines': []
        }
    
    def generate_bulk_signals(self, symbols: List[str], max_workers: int = 12) -> List[Dict]:
        """Generate signals for multiple symbols efficiently - optimized for 117 stocks"""
        logger.info(f"Generating signals for {len(symbols)} symbols using comprehensive sentiment...")
        
        # Pre-fetch sentiment data for all symbols
        if self.sentiment_service:
            logger.info("Pre-fetching comprehensive sentiment data...")
            sentiment_batch = self.sentiment_service.get_sentiment_batch(symbols)
            logger.info(f"Pre-fetched sentiment data for {len(sentiment_batch)} symbols")
        
        signals = []
        
        # Process signals in parallel with optimized worker count for 117 stocks
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_symbol = {
                executor.submit(self.generate_signal, symbol): symbol 
                for symbol in symbols
            }
            
            for future in as_completed(future_to_symbol):
                symbol = future_to_symbol[future]
                try:
                    signal = future.result()
                    signals.append(signal)
                except Exception as e:
                    logger.error(f"Error generating signal for {symbol}: {e}")
                    signals.append(self._generate_fallback_signal(symbol))
        
        # Sort by confidence
        signals.sort(key=lambda x: x['confidence'], reverse=True)
        
        logger.info(f"Generated {len(signals)} signals using comprehensive sentiment")
        return signals

    def _create_fallback_model(self):
        """Create a simple fallback model when the trained model can't be loaded"""
        try:
            import torch.nn as nn
            
            class SimpleV5Model(nn.Module):
                def __init__(self, input_dim=5, hidden_dim=32, output_dim=1):
                    super().__init__()
                    self.layers = nn.Sequential(
                        nn.Linear(input_dim, hidden_dim),
                        nn.ReLU(),
                        nn.Dropout(0.2),
                        nn.Linear(hidden_dim, hidden_dim // 2),
                        nn.ReLU(),
                        nn.Dropout(0.2),
                        nn.Linear(hidden_dim // 2, output_dim),
                        nn.Tanh()  # Output between -1 and 1
                    )
                    
                def forward(self, x):
                    return self.layers(x)
            
            model = SimpleV5Model()
            model.eval()
            logger.info("âœ… Created fallback V5 model")
            return model
            
        except Exception as e:
            logger.error(f"Error creating fallback model: {e}")
            return None

    def generate_kelly_recommendation(self, symbol: str, signal_data: Dict, 
                                    portfolio_value: float = 1000000) -> Dict[str, float]:
        """
        Generate Kelly Criterion recommendation for position sizing
        
        Args:
            symbol: Stock symbol
            signal_data: Signal data with confidence and direction
            portfolio_value: Total portfolio value
            
        Returns:
            dict: Kelly recommendation with position sizing
        """
        try:
            signal_confidence = signal_data.get('confidence', 0.5)
            signal_direction = signal_data.get('signal', 'HOLD')
            volatility = signal_data.get('volatility', 0.2)
            
            # Calculate signal-based Kelly
            kelly_metrics = self.kelly_engine.calculate_signal_based_kelly(
                signal_confidence=signal_confidence,
                signal_direction=signal_direction,
                volatility=volatility
            )
            
            # Get position size recommendation
            position_recommendation = self.kelly_engine.get_position_size_recommendation(
                symbol=symbol,
                kelly_metrics=kelly_metrics,
                portfolio_value=portfolio_value
            )
            
            # Combine metrics
            recommendation = {
                'symbol': symbol,
                'signal_direction': signal_direction,
                'signal_confidence': signal_confidence,
                'kelly_fraction': kelly_metrics['kelly_fraction'],
                'safe_kelly_fraction': kelly_metrics['safe_kelly_fraction'],
                'recommended_position_size': position_recommendation['position_size_percent'],
                'recommended_position_value': position_recommendation['recommended_position_value'],
                'max_loss_percent': position_recommendation['max_loss_percent'],
                'volatility': volatility,
                'recommendation_strength': kelly_metrics['recommendation_strength'],
                'risk_level': self._get_risk_level(kelly_metrics['safe_kelly_fraction']),
                'timestamp': datetime.now().isoformat()
            }
            
            logger.info(f"[KELLY] {symbol} - Kelly: {kelly_metrics['safe_kelly_fraction']:.4f}, "
                       f"Position: {position_recommendation['position_size_percent']:.2f}%")
            
            return recommendation
            
        except Exception as e:
            logger.error(f"Error generating Kelly recommendation for {symbol}: {e}")
            return {
                'symbol': symbol,
                'signal_direction': signal_data.get('signal', 'HOLD'),
                'signal_confidence': signal_data.get('confidence', 0.5),
                'kelly_fraction': 0.0,
                'safe_kelly_fraction': 0.0,
                'recommended_position_size': 0.0,
                'recommended_position_value': 0.0,
                'max_loss_percent': 0.0,
                'volatility': signal_data.get('volatility', 0.2),
                'recommendation_strength': 0.0,
                'risk_level': 'LOW',
                'timestamp': datetime.now().isoformat()
            }
    
    def _get_risk_level(self, kelly_fraction: float) -> str:
        """Get risk level based on Kelly fraction"""
        if kelly_fraction > 0.1:
            return 'HIGH'
        elif kelly_fraction > 0.05:
            return 'MEDIUM'
        elif kelly_fraction > 0.02:
            return 'LOW'
        else:
            return 'VERY_LOW'

# Global instance
signal_generator_v2 = None

def get_signal_generator_v2():
    """Get the global signal generator instance"""
    global signal_generator_v2
    if signal_generator_v2 is None:
        signal_generator_v2 = EnhancedSignalGeneratorV2()
    return signal_generator_v2

if __name__ == "__main__":
    # Test the enhanced signal generator
    print("ðŸš€ Testing Enhanced Signal Generator V2...")
    
    generator = EnhancedSignalGeneratorV2()
    
    # Test single signal generation
    test_symbols = ['RELIANCE.NSE', 'TCS.NSE', 'HDFCBANK.NSE']
    
    print("\nðŸ“Š Testing single signal generation:")
    for symbol in test_symbols:
        signal = generator.generate_signal(symbol)
        print(f"{symbol}: {signal['signal']} (confidence: {signal['confidence']:.3f}, sentiment: {signal['intraday_sentiment']:.3f})")
    
    # Test bulk signal generation
    print("\nðŸ“ˆ Testing bulk signal generation:")
    bulk_signals = generator.generate_bulk_signals(test_symbols, max_workers=2)
    print(f"Generated {len(bulk_signals)} bulk signals")
    
    for signal in bulk_signals:
        print(f"{signal['symbol']}: {signal['signal']} (confidence: {signal['confidence']:.3f})")
    
    print("\nâœ… Enhanced Signal Generator V2 test completed!") 